{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evsi8432/opt/anaconda3/lib/python3.9/site-packages/scipy/__init__.py:155: UserWarning: A NumPy version >=1.18.5 and <1.25.0 is required for this version of SciPy (detected version 1.26.4\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.special import logsumexp\n",
    "sys.path.append('vbpi-torch/rooted')\n",
    "\n",
    "import torch\n",
    "from dataManipulation import *\n",
    "from treeManipulation import *\n",
    "from utils import tree_summary, summary, summary_raw, get_support_info\n",
    "from vbpi import VBPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#from autograd_gamma import gamma, gammainc, gammaincc, gammaincln, gammainccln\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import deepcopy\n",
    "from itertools import product\n",
    "from itertools import combinations\n",
    "import pickle\n",
    "\n",
    "from io import StringIO\n",
    "from Bio import Phylo\n",
    "\n",
    "from tree_torch import Tree\n",
    "from SLCVI_torch import SLCVI\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = \"DS9\"\n",
    "pop_size = 5.0 # exponential parameter for constant pop size prior\n",
    "\n",
    "# initialize models\n",
    "models = {\"reinforce\": {},\n",
    "          \"reparam\": {},\n",
    "          \"VIMCO\": {},\n",
    "          \"VBPI\": {}}\n",
    "\n",
    "data_file = '../dat/'+data_set+'/'+data_set+'.pickle'\n",
    "\n",
    "# models\n",
    "models = [\"reparam\",\"reinforce\",\"BEAST\",\"VBPI\"]\n",
    "\n",
    "# Beast file\n",
    "BEAST_pref = '../dat/'+data_set+'/'+data_set+'_MLL_'\n",
    "BEAST_burnin = 250000\n",
    "\n",
    "# VPBI files\n",
    "VBPI_dir = '../results/'+data_set+'/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Requirements for VBPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the sequence data and estimate the subsplit support\n",
    "data, taxa = loadData('../dat/'+data_set+'/'+data_set+'.nexus', 'nexus')\n",
    "mcmc_support_trees_dict, mcmc_support_trees_wts = summary('../dat/'+data_set+'/'+data_set+'_fixed_pop_support_short_run', 'nexus', burnin=250)\n",
    "rootsplit_supp_dict, subsplit_supp_dict = get_support_info(taxa, mcmc_support_trees_dict)\n",
    "#del mcmc_support_trees_dict, mcmc_support_trees_wts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the ground truth\n",
    "#mcmc_sampled_trees_dict, mcmc_sampled_trees_wts, _ = tree_summary('../dat/DS1/DS1_fixed_pop_golden_run.trees', 'nexus', burnin=25001)\n",
    "emp_tree_freq = None#{mcmc_sampled_trees_dict[tree_id]: tree_wts for tree_id, tree_wts in sorted(mcmc_sampled_trees_wts.items(), key=lambda x:x[1], reverse=True)}\n",
    "sample_info = [0.0 for taxon in taxa]\n",
    "#del mcmc_sampled_trees_dict, mcmc_sampled_trees_wts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up the model\n",
    "VBPI_models = {}\n",
    "VBPI_models[\"10\"] = VBPI(taxa, rootsplit_supp_dict, subsplit_supp_dict, data, pden=np.ones(4)/4., subModel=('JC', 1.0),\n",
    "             emp_tree_freq=emp_tree_freq, root_height_offset=0.0, clock_rate=1.0, psp=True,\n",
    "             sample_info=sample_info, coalescent_type='fixed_pop', clock_type='fixed_rate',\n",
    "             log_pop_size_offset=math.log(5.0))\n",
    "\n",
    "VBPI_models[\"20\"] = VBPI(taxa, rootsplit_supp_dict, subsplit_supp_dict, data, pden=np.ones(4)/4., subModel=('JC', 1.0),\n",
    "             emp_tree_freq=emp_tree_freq, root_height_offset=0.0, clock_rate=1.0, psp=True,\n",
    "             sample_info=sample_info, coalescent_type='fixed_pop', clock_type='fixed_rate',\n",
    "             log_pop_size_offset=math.log(5.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load in the relevant files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# VBPI\n",
    "VBPI_runtimes = {}\n",
    "VBPI_lbs = {}\n",
    "VBPI_iters = {}\n",
    "\n",
    "legend = []\n",
    "\n",
    "for bs in [\"10\",\"20\"]:\n",
    "    \n",
    "    VBPI_runtimes[bs] = None\n",
    "    VBPI_lbs[bs] = None\n",
    "    VBPI_iters[bs] = None\n",
    "    lb_star = -np.infty\n",
    "    \n",
    "    for ss in [\"0.001\",\"0.0001\",\"1e-05\"]:\n",
    "        VBPI_pref = \"mcmc_vimco_%s_%s_psp_fixed_pop_fixed_rate_\"%(bs,ss)\n",
    "        files = [x for x in os.listdir(VBPI_dir) if x.startswith(VBPI_pref)]\n",
    "        \n",
    "        VBPI_runtimes0 = np.load(VBPI_dir+max([x for x in files if x.endswith(\"_run_time.npy\")]))\n",
    "        VBPI_lbs0 = np.load(VBPI_dir+max([x for x in files if x.endswith(\"_test_lb.npy\")]))\n",
    "        VBPI_iters0 = np.load(VBPI_dir+max([x for x in files if x.endswith(\"_iters.npy\")]))\n",
    "        \n",
    "        if max(VBPI_lbs0) > lb_star:\n",
    "            VBPI_runtimes[bs] = VBPI_runtimes0\n",
    "            VBPI_lbs[bs] = VBPI_lbs0\n",
    "            VBPI_iters[bs] = VBPI_iters0\n",
    "            VBPI_models[bs].load_from(VBPI_dir+max([x for x in files if x.endswith(\".pt\")]))\n",
    "            lb_star = max(VBPI_lbs0)\n",
    "            \n",
    "    plt.plot(np.cumsum(VBPI_runtimes[bs])/3600,VBPI_lbs[bs])\n",
    "    plt.xlabel(\"runtime (hours)\")\n",
    "    #plt.plot(VBPI_iters[bs],VBPI_lbs[bs])\n",
    "    #plt.xlabel(\"Iteration\")\n",
    "    legend.append(\"VIMCO, K = %s\"%(bs))  \n",
    "\n",
    "plt.ylabel(\"ELBO\")\n",
    "plt.legend(legend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEAST\n",
    "def load_beast(data_set,i,burnin):\n",
    "    df = pd.read_csv('../dat/'+data_set+'/'+data_set+'_fixed_pop_MLL_%d.log'%i, \n",
    "                     sep = '\\t',skiprows=[0,1,2])\n",
    "    df = df[df.state > burnin]\n",
    "    return df\n",
    "\n",
    "BEAST_data = pd.concat([load_beast(data_set,i,BEAST_burnin) for i in range(1,11)])\n",
    "BEAST_MLLs = []\n",
    "\n",
    "# extract MLL from beast log\n",
    "for i in range(1,11):\n",
    "    with open('../dat/'+data_set+'/'+data_set+\"_MLL_%d.txt\"%i, \"r\") as text_file:\n",
    "        line = text_file.readlines()[-4]\n",
    "    ind = np.where([not x in \"-1234567890.\" for x in line])[0][-2]\n",
    "    BEAST_MLLs.append(float(line[(ind+1):-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my models\n",
    "optims = {}\n",
    "settings = {}\n",
    "ELBO_star = -np.infty\n",
    "ELBO_min = np.infty\n",
    "ELBO_max = -np.infty\n",
    "legend = []\n",
    "    \n",
    "for model in [\"reinforce\",\"reparam\",\"reinforce_VIMCO\"]:\n",
    "    \n",
    "    optims[model] = None\n",
    "    \n",
    "    for dy in [\"none\",\"linear\",\"exp\"]:\n",
    "        \n",
    "        ELBO_star = -np.infty\n",
    "    \n",
    "        for ss in [0.1,0.03,0.01,0.003,0.001,0.0003,0.0001]:\n",
    "            \n",
    "            optim_dir = '../results/'+data_set+'/'\n",
    "            optim_pref = data_set+'_'+model+'_'+dy+'_'+str(ss)\n",
    "            files = [x for x in os.listdir(optim_dir) if x.startswith(optim_pref)]\n",
    "            \n",
    "            if not files:\n",
    "                print(optim_pref + \" does not exist. Continuing...\")\n",
    "                continue\n",
    "            \n",
    "            fname = optim_dir + max(files)\n",
    "    \n",
    "            with open(fname, 'rb') as f:\n",
    "                optim0 = pickle.load(f)\n",
    "            \n",
    "            if optim0.ELBO_ests[-1] > ELBO_star:\n",
    "                optims[model] = optim0\n",
    "                settings[model] = (ss,dy)\n",
    "                ELBO_star = optim0.ELBO_ests[-1]\n",
    "                \n",
    "    if max(optims[model].ELBO_ests) > ELBO_max:\n",
    "        ELBO_max = max(optims[model].ELBO_ests)\n",
    "\n",
    "    if min(optims[model].ELBO_ests) < ELBO_min:\n",
    "        ELBO_min = min(optims[model].ELBO_ests)\n",
    "                \n",
    "    plt.plot(np.cumsum(optims[model].run_times)/3600,optims[model].ELBO_ests)\n",
    "    #plt.plot(optims[model].epochs,optims[model].ELBO_ests)\n",
    "    legend.append(model+\" \"+str(settings[model][0])+\" \"+settings[model][1])\n",
    "        \n",
    "for bs in [\"10\",\"20\"]:\n",
    "    plt.plot(np.cumsum(VBPI_runtimes[bs])/3600,VBPI_lbs[bs])\n",
    "    #plt.plot(VBPI_iters[bs],VBPI_lbs[bs])\n",
    "    legend.append(\"Baseline VIMCO, K = %s\"%(bs))  \n",
    "\n",
    "plt.xlabel(\"runtime (hours)\")\n",
    "#plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"ELBO\")\n",
    "plt.legend(legend)\n",
    "plt.ylim([ELBO_min-10,ELBO_max+10])\n",
    "plt.savefig('../plt/'+data_set+'/'+data_set+'_ELBO_v_time.png')\n",
    "plt.ylim([ELBO_max-10,ELBO_max+10])\n",
    "plt.savefig('../plt/'+data_set+'/'+data_set+'_ELBO_v_time_zoom.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "legend = []\n",
    "    \n",
    "for model in [\"reinforce_VIMCO\",\"reinforce\",\"reparam\"]:\n",
    "                \n",
    "        plt.plot(np.cumsum(optims[model].run_times)/3600,np.log(optims[model].grad_norms))\n",
    "        legend.append(model)\n",
    "\n",
    "plt.xlabel(\"runtime (hours)\")\n",
    "plt.ylabel(\"grad_norm\")\n",
    "plt.legend(legend)\n",
    "plt.savefig('../plt/'+data_set+'/'+data_set+'_grad_norm_v_time.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# draw the random tree using a newick file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_newick(node):\n",
    "\n",
    "    if node.children == []:\n",
    "        return species[next(iter(node.leaves))] + \":\" + str(node.parent.coal_time.item())\n",
    "    elif node.parent is None:\n",
    "        return \"(\" + write_newick(node.children[0]) + \",\" + write_newick(node.children[1]) + \")\"\n",
    "    else:\n",
    "        bl = node.parent.coal_time.item() - node.coal_time.item()\n",
    "        return \"(\" + write_newick(node.children[0]) + \",\" + write_newick(node.children[1]) + \"):\" + str(bl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "theta = torch.tensor(optims['reinforce'].theta)\n",
    "\n",
    "with open(data_file, 'rb') as f:\n",
    "    DS = pickle.load(f)\n",
    "\n",
    "genomes = []\n",
    "species = []\n",
    "for key in DS:\n",
    "    genomes.append(DS[key])\n",
    "    species.append(key)\n",
    "    \n",
    "n_species = len(species)\n",
    "\n",
    "# From https://github.com/zcrabbit/vbpi-torch/blob/ff86cf0c47a5753f5cc5b4dfe0b6ed783ab22669/unrooted/phyloModel.py#L7-L11\n",
    "nuc2vec = {'A':[1.,0.,0.,0.], 'G':[0.,1.,0.,0.], 'C':[0.,0.,1.,0.], 'T':[0.,0.,0.,1.],\n",
    "           '-':[1.,1.,1.,1.], '?':[1.,1.,1.,1.], 'N':[1.,1.,1.,1.], 'R':[1.,1.,0.,0.],\n",
    "           'Y':[0.,0.,1.,1.], 'S':[0.,1.,1.,0.], 'W':[1.,0.,0.,1.], 'K':[0.,1.,0.,1.],\n",
    "           'M':[1.,0.,1.,0.], 'B':[0.,1.,1.,1.], 'D':[1.,1.,0.,1.], 'H':[1.,0.,1.,1.],\n",
    "           'V':[1.,1.,1.,0.], '.':[1.,1.,1.,1.], 'U':[0.,0.,0.,1.]}\n",
    "\n",
    "tree_log_probs = torch.tensor([[nuc2vec[g] for g in genome] for genome in genomes],\n",
    "                                dtype = torch.float64)\n",
    "tree_log_probs = torch.log(tree_log_probs)\n",
    "\n",
    "for _ in range(10):\n",
    "    Z = torch.normal(mean=0.0,std=1.0,size=(n_species,n_species))\n",
    "    log_times = torch.exp(theta[1])*Z+theta[0]\n",
    "    log_times = log_times + torch.triu(torch.full((n_species,n_species), float(\"Inf\")))\n",
    "    log_times = log_times.detach()\n",
    "\n",
    "    tree = Tree(theta,log_times,tree_log_probs,\n",
    "                pop_size=pop_size)\n",
    "\n",
    "\n",
    "    treedata = write_newick(tree.nodes[-1])\n",
    "    handle = StringIO(treedata)\n",
    "    tree_to_draw = Phylo.read(handle, \"newick\")\n",
    "\n",
    "    # Set up the plot\n",
    "    fig = plt.figure(figsize=(12, 10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "\n",
    "    # Draw the phylogenetic tree\n",
    "    Phylo.draw(tree_to_draw, axes=ax)\n",
    "\n",
    "    print(tree.log_like)\n",
    "    print(tree.log_prior)\n",
    "    print(tree.log_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot estimated ELBO over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_lengths = {}\n",
    "root_heights = {}\n",
    "log_likes = {}\n",
    "log_priors = {}\n",
    "log_qs = {}\n",
    "MLLs = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data from BEAST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get lengths from BEAST\n",
    "tree_lengths[\"BEAST\"] = BEAST_data.treeLength[BEAST_data.state > BEAST_burnin].to_numpy()\n",
    "root_heights[\"BEAST\"] = BEAST_data['treeModel.rootHeight'][BEAST_data.state > BEAST_burnin].to_numpy()\n",
    "log_likes[\"BEAST\"] = BEAST_data.likelihood[BEAST_data.state > BEAST_burnin].to_numpy()\n",
    "log_priors[\"BEAST\"] = BEAST_data.prior[BEAST_data.state > BEAST_burnin].to_numpy()\n",
    "\n",
    "MLLs[\"BEAST\"] = BEAST_MLLs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data from VBPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = VBPI_models[\"10\"]\n",
    "n_runs = 1000\n",
    "n_particles = 1\n",
    "\n",
    "root_heights[\"VBPI\"] = []\n",
    "tree_lengths[\"VBPI\"] = []\n",
    "log_priors[\"VBPI\"] = []\n",
    "log_likes[\"VBPI\"] = []\n",
    "MLLs[\"VBPI\"] = []\n",
    "\n",
    "for i in range(n_runs):\n",
    "    print(i)\n",
    "    with torch.no_grad():\n",
    "        samp_trees = [self.tree_model.sample_tree() for particle in range(n_particles)]\n",
    "        [namenum(tree, self.taxa) for tree in samp_trees]\n",
    "        logq_tree = torch.stack([self.logq_tree(tree) for tree in samp_trees])\n",
    "\n",
    "        samp_branch, logq_height, height, event_info = self.branch_model(samp_trees)\n",
    "        log_clock_rate, logq_clock_rate = self.clock_model.sample(n_particles=n_particles)\n",
    "        samp_branch = samp_branch.to(torch.float32) * log_clock_rate.exp()\n",
    "        logll = torch.stack([self.phylo_model.loglikelihood(branch, tree) for branch, tree in zip(*[samp_branch, samp_trees])])\n",
    "\n",
    "        self.tree_prior_model.update_batch(height, event_info)\n",
    "        coalescent_param, logq_prior = self.tree_prior_model.sample_pop_size(n_particles=n_particles)\n",
    "        logp_coalescent_prior, _ = self.tree_prior_model(coalescent_param, False)\n",
    "\n",
    "        logp_clock_rate = self.clock_model(log_clock_rate)\n",
    "\n",
    "        # get values\n",
    "        root_heights[\"VBPI\"].extend(list(height[:,0].numpy()))\n",
    "        tree_lengths[\"VBPI\"].extend(list(np.sum(samp_branch.numpy(),axis=1)))\n",
    "        log_priors[\"VBPI\"].extend(list(logp_coalescent_prior.numpy() + logp_clock_rate))\n",
    "        log_likes[\"VBPI\"].extend(list(logll.numpy()))\n",
    "        MLLs[\"VBPI\"].append(torch.logsumexp(logll + logp_coalescent_prior + logp_clock_rate - logq_tree - logq_height - logq_prior - logq_clock_rate - math.log(n_particles), 0).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get data from my code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tree_length(tree):\n",
    "    tree_length = 0\n",
    "    for leaf in tree.leaves:\n",
    "        tree_length += leaf.parent.coal_time.item() - leaf.coal_time\n",
    "\n",
    "    for node in tree.nodes[:-1]:\n",
    "        tree_length += node.parent.coal_time.item() - node.coal_time.item()\n",
    "        \n",
    "    return tree_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_exp = 100\n",
    "n_particles = 1\n",
    "\n",
    "for model in [\"reparam\",\"reinforce\",\"reinforce_VIMCO\"]:\n",
    "    with torch.no_grad():\n",
    "        theta = optims[model].theta\n",
    "\n",
    "        root_heights[model] = []\n",
    "        tree_lengths[model] = []\n",
    "        log_priors[model] = []\n",
    "        log_likes[model] = []\n",
    "        MLLs[model] = []\n",
    "\n",
    "        for i in range(n_exp):\n",
    "            print(i)\n",
    "            p_minus_qs = []\n",
    "\n",
    "            for j in range(n_particles):\n",
    "\n",
    "                Z = torch.normal(mean=0.0,std=1.0,size=(n_species,n_species))\n",
    "                log_times = torch.exp(theta[1])*Z+theta[0]\n",
    "                log_times = log_times + torch.triu(torch.full((n_species,n_species), float(\"Inf\")))\n",
    "                log_times = log_times.detach()\n",
    "                tree = Tree(theta,log_times,deepcopy(tree_log_probs),\n",
    "                            pop_size=pop_size)\n",
    "\n",
    "                p_minus_qs.append(tree.log_p.item() - tree.log_q.item())\n",
    "\n",
    "                log_likes[model].append(tree.log_like.item())\n",
    "                log_priors[model].append(tree.log_prior.item())\n",
    "                root_heights[model].append(tree.nodes[-1].coal_time.item())\n",
    "                tree_lengths[model].append(get_tree_length(tree))\n",
    "\n",
    "            MLLs[model].append(logsumexp(p_minus_qs) - np.log(n_particles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_hist(data,title):  \n",
    "    \n",
    "    keys = list(data.keys())\n",
    "    _, bins, _ = plt.hist(data[keys[0]], bins = 100, alpha = 0.5, density=True)\n",
    "\n",
    "    for key in keys[1:]:\n",
    "        plt.hist(data[key], bins = bins, alpha = 0.5, density=True)\n",
    "\n",
    "    plt.legend(keys)\n",
    "    plt.xlabel(title)\n",
    "    plt.ylabel(\"density\")\n",
    "    plt.savefig('../plt/'+data_set+'/'+data_set+'_'+title+'_hist.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(tree_lengths,\"Tree Lengths\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(root_heights,\"Root Heights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(log_priors,\"Log Prior\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(log_likes,\"Log Likelihood\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the dictionary\n",
    "MLLs0 = MLLs.copy()\n",
    "del MLLs0['BEAST']\n",
    "plot_hist(MLLs0,\"ELBOs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MLLs:\")\n",
    "print(\"\")\n",
    "for key in MLLs:\n",
    "    print(\"%s: %s\"%(key,logsumexp(MLLs[key]) - np.log(len(MLLs[key]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"ELBOs:\")\n",
    "print(\"\")\n",
    "for key in MLLs:\n",
    "    if key != \"BEAST\":\n",
    "        print(\"%s: %s\"%(key,np.mean(MLLs[key])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for theta in [optims[\"reparam\"].theta,\n",
    "              optims[\"reinforce\"].theta,\n",
    "              optims[\"reinforce_VIMCO\"].theta]:\n",
    "    \n",
    "    m = deepcopy(theta[0].detach())\n",
    "    m[np.triu_indices(m.shape[0])] = np.nan\n",
    "    plt.imshow(m)\n",
    "    plt.title(\"means of log-coalscent times\")\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "\n",
    "    log_sig = deepcopy(theta[1].detach())\n",
    "    log_sig[np.triu_indices(log_sig.shape[0])] = np.nan\n",
    "    plt.imshow(log_sig)\n",
    "    plt.title(\"log-std of log-coalscent times\")\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
